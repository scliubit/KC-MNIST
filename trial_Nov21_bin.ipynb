{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from utils import seed_everything, to_var, count_parameters, show_image_grid\n",
    "# from models import VAE\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import gzip\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 => 436 \t ratio: 0.5677083333333334\n"
     ]
    }
   ],
   "source": [
    "# example of compressing a string\n",
    "source = \"\"\"The problem of searching for patterns in data is a fundamental one and has a long and successful history. For instance, the extensive astronomical observations of Tycho Brahe in the 16 century allowed Johannes Kepler to discover the empirical laws of planetary motion, which in turn provided a springboard for the development of clas- sical mechanics. Similarly, the discovery of regularities in atomic spectra played a key role in the development and verification of quantum physics in the early twenti- eth century. The field of pattern recognition is concerned with the automatic discov- ery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories.\"\"\"\n",
    "output = gzip.compress(source.encode(\"utf-8\"))\n",
    "print(len(source), \"=>\", len(output), \"\\t\", \"ratio:\", len(output) / len(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend device: mps\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "seed_everything(42)\n",
    "# CONST TABLE\n",
    "MPS_FLAG = torch.backends.mps.is_available()\n",
    "BATCH_SIZE = 1\n",
    "NUM_SAMPLES = 500\n",
    "K = 5\n",
    "NUM_TEST = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "if MPS_FLAG:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Backend device: {}\".format(device))\n",
    "data_path = \"../datasets/\"\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "dataset1 = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST(data_path, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5000\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "indices = [[] for _ in range(10)]\n",
    "for idx, (_, label) in enumerate(dataset1):\n",
    "    indices[label].append(idx)\n",
    "\n",
    "sampled_indices = []\n",
    "for label_indices in indices:\n",
    "    sampled_indices.extend(np.random.choice(label_indices, NUM_SAMPLES, replace=False))\n",
    "\n",
    "sampled_dataset = Subset(dataset1, sampled_indices)\n",
    "# sampled_loader = DataLoader(sampled_dataset, batch_size=64, shuffle=True)\n",
    "print(\"Number of samples:\", len(sampled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8650402016\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "\n",
    "def f_compress(image: torch.Tensor) -> List[int]:\n",
    "    # image = torch.round(image)  # round(image)\n",
    "    image = image > 0.5\n",
    "    image_flat = image.flatten().numpy().astype(np.uint8)\n",
    "    # print(image_flat.dtype)\n",
    "    image_string = \"\".join(image_flat.astype(str))\n",
    "    # print(image_string)\n",
    "    # image_string = \"\".join([str(int(i)) for i in image_flat])\n",
    "    # chunks = [image_string[i : i + 8] for i in range(0, len(image_string), 8)]\n",
    "    # image_bytes = bytes([int(chunk, 2) for chunk in chunks])\n",
    "    image_compressed = gzip.compress(image_string.encode())\n",
    "    return [len(image_compressed), image_compressed, image_string]\n",
    "\n",
    "\n",
    "def f_compress_mutual(image: torch.Tensor) -> List[int]:\n",
    "    # print(image.shape)\n",
    "    fc_1, compress_str_1, image_bytes_1 = f_compress(image[:, :, 0])\n",
    "    fc_2, compress_str_2, image_bytes_2 = f_compress(image[:, :, 1])\n",
    "    image_string_joint = \" \".join([image_bytes_1.decode(), image_bytes_2.decode()])\n",
    "    image_compressed = gzip.compress(image_string_joint.encode())\n",
    "    return [len(image_compressed), image_compressed]\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "correct_percentage = 0\n",
    "cnt = 0\n",
    "for test_image, test_label in dataset2:\n",
    "    # print(test_image.squeeze().shape, test_label)\n",
    "    fc_1, _, __ = f_compress(test_image.squeeze())\n",
    "    # print(fc_1,len(__))\n",
    "    # break\n",
    "    # print(fc_1)\n",
    "    distance_from_1 = []\n",
    "    for train_image, train_label in sampled_dataset:\n",
    "        fc_2, _, __ = f_compress(train_image.squeeze())\n",
    "        # 0.72\n",
    "        # image_agg = torch.stack([test_image.squeeze(), train_image.squeeze()], -1)\n",
    "        # 0.74\n",
    "        image_agg = torch.stack([train_image.squeeze(), test_image.squeeze()], -1)\n",
    "        fc_3, _, __ = f_compress(image_agg)\n",
    "        # fc_3,_ = f_compress_mutual(image_agg)\n",
    "        # print(fc_1, fc_2, fc_3)\n",
    "        NCD = (fc_3 - min(fc_1, fc_2)) / max(fc_1, fc_2)\n",
    "        distance_from_1.append(NCD)\n",
    "    sorted_idx = np.argsort(np.array(distance_from_1))\n",
    "    top_k_class = [sampled_dataset[i][1] for i in sorted_idx[:K]]\n",
    "    # sampled_dataset[sorted_idx[:K],1]\n",
    "    predict_class = max(set(top_k_class), key=top_k_class.count)\n",
    "    if predict_class == test_label:\n",
    "        correct_percentage += 1\n",
    "    cnt += 1\n",
    "    print(cnt, correct_percentage / cnt, end=\"\\r\")\n",
    "    if cnt == NUM_TEST:\n",
    "        break\n",
    "print(\"Accuracy:\", correct_percentage / NUM_TEST)\n",
    "# 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
